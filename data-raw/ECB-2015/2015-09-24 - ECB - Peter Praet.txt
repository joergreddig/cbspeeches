It is a pleasure for me to share with you some thoughts on the topic of this conference. Let me start with a word of caution. I think we are not yet in a position to draw firm lessons. The final verdict on many aspects of the crisis and the way policy-makers, including central bankers, reacted to it - both globally and in their respective jurisdictions - is still out. Therefore, somewhat less ambitiously, please allow me to offer some remarks on the conference topic.
Based on my own experience, the overarching challenge that was faced by major central banks in terms of their response to the recent financial crisis can be captured with two insights.
First, when the crisis intensified at a global level, we faced a trade-off we had not seen for a very long time, namely how to prevent the meltdown of the financial system without causing undue harm to the incentive constraints that are of vital importance for the functioning of market-based economies. The pre-crisis macroeconomic debate had spent considerable time and effort explaining that negative supply side shocks could present central bankers with a very difficult decision: whether to stabilise inflation at the cost of slowing growth further, or be more patient at bringing inflation back to target at the cost of destabilising inflation expectations. We thought that a situation like this was the worst scenario for central bankers. Therefore, when we finally faced the post-Lehman Brothers meltdown and the different - and far more serious - decision of handling panic against preserving incentives, the required experience on how to deal with it had, to some extent, been lost. We could consult history books - the recurrent financial crises of the 19th century were regularly haunting central bankers - but not macroeconomic textbooks.
Second, while a global meltdown had successfully been prevented, a second type of trade-off emerged, which is typical for balance sheet recessions. What essentially had happened is that banks, emerging painfully from a liquidity crisis, had started to deleverage actively in an attempt to structurally reduce liquidity needs by shedding excess exposures. The deleveraging was an additional downside force contributing to the slump. In this situation, a central banker is again torn between two priorities. You want banks to reduce excess exposures, because this is a precondition for the economy to return to healthy growth. In other words, you would like banks to deleverage in an orderly way. At the same time, you face the danger that, at the aggregate level, any type of credit contraction will undermine demand severely, and a deeper contraction will make it difficult or impossible for the central bank to deliver on its price stability mandate.
True, you can also argue that central banks have some leeway - within their mandate - to facilitate the needed adjustments. For example, the time horizon for normalising inflation is generally not set in calendar time, and is often made conditional on shocks. This allows the central bank to accept more disinflation - and for longer - during the transition than it would tolerate in different balance sheet conditions. But there is a limit to this. The reason central banks have been given mandates that are expressed in terms of numerical objectives for inflation is because legislatures realised that central banks' discretion had to be constrained. Their reaction functions had to be made predictable within a horizon which is realistic and, at the same time, verifiable by electorates.
So, what is the role of monetary policy in this scenario? Maintaining a very accommodative policy stance for too long certainly carries significant risks. Incentives for timely balance sheet repair may be undermined and new imbalances may ultimately emerge. Still, central banks will have to remain true to their mandates of ensuring price stability. This mandate should be interpreted as a symmetric mandate. Too low inflation, or even deflation, for a prolonged period of time cannot be seen as consistent with price stability.
This is the overarching challenge, as I see it, and I will come back to some of the elements involved in more detail. I will now turn to three specific remarks of global relevance, before I make two concluding observations that are specific to the euro area.
At a global level, the financial crisis created an environment in which many central banks resorted to unconventional measures because the conventional instrument, the short-term policy rate, had become constrained by the lower bound. In the jargon of papers written before the crisis, it is simple to say what happened: many central banks hit the famous zero lower bound (ZLB). The euro area, as I will mention at the end, reached the lower bound through a different avenue. And the end point of that journey, as you know, was not zero, but a negative point.
The ZLB constraint has turned out to be more binding than previously thought.
What was the pre-crisis consensus?
As concerns the United States, let me quote from the paper entitled “Have We Underestimated the Likelihood and Severity of Zero Lower Bound Events?”, written by John Williams and co-authors working for the Board of Governors of the Federal Reserve System. The paper documents predictions from the Fed's FRB/US model (a large-scale macroeconometric model) for the frequency and duration of ZLB episodes. The key finding is that, “if monetary policy followed the prescriptions of the standard Taylor (1993) rule with an inflation target of 2 percent, the federal funds rate would be near zero about 5 percent of the time and the “typical” ZLB episode would last four quarters”. Moreover, “the ZLB would have relatively minor effects on macroeconomic performance under these policy assumptions.”
With regard to the euro area, you may recall that zero lower bound considerations were a relevant concern for the ECB's strategy review in 2003. At that time, the Governing Council clarified that, within the ECB's definition of price stability of positive inflation rates below 2 percent, it would aim to maintain inflation rates “below, but close to, 2 percent” over the medium term. This clarification was seen to offer a safety margin away from zero nominal interest rates and zero or negative inflation rates. In this spirit, the overview of the background studies concluded that “most available studies indicate that the likelihood [of hitting the ZLB] decreases to very low levels when the objective of the central bank is to set an inflation rate above 1 percent”.
These quotes describe the view which prevailed prior to the crisis. But today, for the United States, it is nearly seven years ago that the bound was reached. And for the euro area, seven years after the collapse of Lehman Brothers, we are still struggling with headline inflation near zero. Most likely, it will still take some time before the Governing Council's aim of levels below but close to 2 percent is reached. Current ECB staff projections foresee inflation at 1.7 percent by the end of our projection horizon, 2017.
So, what was overlooked in pre-crisis times? Going beyond the fact that the crisis caught us “culturally unprepared” as I tried to say before, the answer is a combination of factors. At a deeper level, models had been shaped too much by the Great Moderation period. They were lacking structural relationships, propagation mechanisms and shocks that have become globally relevant since the onset of the crisis. One example may suffice to make the point: the likelihood of ZLB events depends strongly on what you assume for the equilibrium real rate. A level of 2 percent, an assumption often made in pre-crisis models, is far from “innocent”: If you estimate the frequency of lower bound hits by shocking a model whose steady state nominal interest rate is 4 percent, because the real rate of equilibrium is assumed to be 2 percent and 2 percent is steady state inflation, the occurrences of zero or negative interest rates will be much fewer than if you start from a steady state of 3 percent (2 percent inflation and 1 percent natural rate). With hindsight, it seems safe to point out that models were by and large lacking features like a non-trivial financial side, sufficient consideration of demographic developments and deep global linkages.
In sum, it seems that it was not only the general design of the mainstream pre-crisis models that made them inadequate for interpreting the crisis, but also the fact that they relied on data mostly drawn from the time of the Great Moderation.
At the lower bound, monetary policy has remained effective via non-standard measures.
Before the crisis, central bankers were aware that non-standard monetary policies would be required when the main policy rate reached the zero lower bound. However, the effectiveness of these policies was not taken as given. Prominent lines of research, for example, had been debating the irrelevance of central bank asset purchases. Today, with the benefit of several years of experience of implementing such policies, central banks have shown these policies to be effective. They have demonstrated that monetary policy has the necessary toolkit to influence the yield curve along different horizons, including the use of forward guidance.
Indeed, this capability acts as a counterargument to the proposal that the ZLB restriction should be overcome via the adoption of a higher inflation target. It seems that the hurdle for this suggestion has become even higher. A shift to a higher inflation target would not only raise significant credibility issues ? we should also remember that prevailing definitions of price stability have a welfare foundation. Everything else being equal, higher inflation objectives inevitably come together with distortions that are harmful from a welfare perspective.
Meanwhile, we are still furthering our understanding of the many features which characterise non-standard measures. Empirically, estimates of the effects of such measures on activity and inflation vary sizeably across studies. And inflation remains below central banks' targets in many jurisdictions. At a conceptual level, the discussion on shadow rate measures shows how difficult it is to find a metric which makes the various dimensions of large-scale asset purchases comparable with ordinary rate cuts. We all grew accustomed to measuring the stance through the Taylor rules. But when a central bank intervenes on the long end of the curve, the stimulus that is injected through those interventions escapes the simple Taylor metric, which is centred on the short end where the lower bound binds. The shadow rate attempts to re-establish the status of the short-term interest rate as a signal of monetary conditions by including information on how unconventional policies alter broader financing conditions. The idea is very appealing. But we need to test these new measures - which yield very disperse measures of the stance - before we can use them in policy work. The potential costs and side-effects from shifting the long end of the yield curve are also a matter of controversy. For example, the profession needs a better understanding of the distributional implications of quantitative easing (QE), although it seems clear that policy inaction in an environment of low growth and high unemployment also has distributional consequences.
In sum, we have seen that unconventional measures are effective in terms of arresting disinflation, preventing fears of a slide into deflation and supporting aggregate demand. But it is fair to say that we need to understand more about their transmission in order to see whether QE can be retained as an instrument that, if not conventional, can play a valuable and reliable role in the toolbox to which central banks can make recourse.
ZLB and non-conventional policies pose extra challenges vis-à-vis normalisation.
Looking ahead, when the monetary policy tightening cycle eventually commences, it is very likely to be different and more challenging than in previous cycles. Just try to picture the recent history of policy rates for some major central banks in a chart. That chart would look odd on both the y-axis and the x-axis: in some major economies, zero has featured for longer than any other value of the policy rate before. This makes some of us think that the non-linearity imparted by the lower bound and generally thought to apply to the policy rate on the way down may exert, for different reasons, an impact also on the way out of the lower bound. The economy may have just gotten too used to that number. For one thing, rate increases will have to be carefully aligned with the normalisation of central bank balance sheets. There will be some division of tasks between instruments to be thought through and organised: what portion of accommodation can be removed - quite conventionally - by raising short-term rates, and what portion by active management of portfolios, i.e. by applying controlled pressure on long-term rates. The profile and evolution of short-term rates and the shape of the term structure will probably look different than in previous normalisation cycles.
The ECB is a long way from these challenges, but other central banks are confronting these as I speak.
In respect of the euro area, these general remarks require some modification. For brevity, let me focus on two aspects.
The ECB hit the lower bound later than many other central banks, and when it did it was not the zero lower bound, but a negative lower bound. Similarly, it resorted at a late stage to large-scale asset purchases.
It stands out that the ECB's monetary policy became distinctly unconventional at an early stage - not least with the adoption of fixed-rate full allotment tenders in its refinancing operations back in 2008, and with short incursions into this unknown territory already in 2007. Moreover, this practice was later expanded to longer horizons, when policy rates still stood at firmly positive levels. This approach was naturally developed in view of the predominantly bank-based nature of the euro area financial system. It led to a rather passive mode of liquidity injection, very much in the tradition of the lender-of-last-resort function of a central bank. This very important tradition owes much to Henry Thornton and Walter Bagehot. But you can read Bagehot without knowing what the ZLB is and how it affects the ability of a central bank to provide stimulus under conditions of insufficient aggregate demand. The ECB adopted a more active control of balance sheet developments only at a much later stage, in the course of last year, ultimately leading to the adoption of the expanded asset purchase programme (APP). Through the APP, via its reliance on outright purchases, the ECB regained a more direct control over the size of the balance sheet. And it was in this context that short-term rates effectively had to reach a lower bound configuration. I think there is little disagreement that, in terms of stimulating demand, this is a precondition for realising the maximum impact of large-scale purchases of securities of various types and maturities via rebalancing and signalling effects.
Let me briefly elaborate on why I said that short-term rates “effectively” had to reach a lower bound configuration. The pre-crisis view, with its focus on the “zero” lower bound created a misleading label. Given that the interest rate on sight deposits held with the Swiss National Bank (SNB) is currently standing at minus 75 basis points, we can rule out that the constraint binds strictly at zero. In the euro area, the interest rate on the deposit facility stands at minus 20 basis points. We have got used to the fact that money market rates (as well as a good range of other interest rates) can be negative. So, one thing we have surely learned is that “zero is rather something minus”. In this particular sense, the “zero” lower bound has turned out to be less binding than previously thought.
In the euro area, negative rates have been powerful in propagating the policy stimulus for two reasons. First, in terms of available policy instruments, negative rates can, to a certain extent, be seen as a substitute for quantitative interventions. Bringing the overnight interest rate to a negative level already in June last year de facto meant that we started generating effects - to a certain degree - that one expects to see under quantitative policies. Second, the negative rate policy complements the channels through which the APP operates. A negative rate on bank reserves is an inducement for banks to lend money balances on and to avoid the tax that would otherwise be paid on them. This should lead to an increase in the velocity of circulation of cash reserves, which is another way to trigger an acceleration in the portfolio rebalancing effect that is a key component in the transmission of asset purchases to the real economy.
Going forward, the effectiveness of monetary policy will improve with a more complete European Monetary Union.
Has the just described special sequencing of the ECB's unconventional monetary policy measures been appropriate? To answer this question, we should recall that the euro area has its own distinct characteristics. And, as a currency union, it is in many ways incomplete. In the language of the “Five Presidents' Report”, “Europe's Economic and Monetary Union (EMU) today is like a house that was built over decades but only partially finished. It is now high time to reinforce its foundations and turn it into what EMU was meant to be”.
This diagnosis explains why, looking back, measures of first resort in other jurisdictions have been measures of last resort in the euro area. In particular, it is clear that, in the euro area, central bank purchases of sovereign debt raise additional questions which are quasi-non-issues in consolidated nation states. And, going forward, this diagnosis also makes it clear why the euro area faces extra challenges. We have to find the right balance in what Markus Brunnermeier recently described as the “stimulus versus reform debate” at the European Economic Association conference in Mannheim.
As I said on the same occasion, in a similar spirit, we need to bring together two different macroeconomic traditions. The “macroeconomic” tradition, by which I pretty much mean the British and “saltwater American” tradition of macroeconomics, with its solid emphasis on demand management. It correctly identifies the need to provide stimulus but may have a tendency to overlook incentives and institutions. Here, a focus on “demand management” may lead to losing sight of the longer term and the incentives that are put in place. The “supply-side” tradition, in all of its incarnations, including the “freshwater American” real business cycle scholars and the older - somewhat forgotten - continental European “institutional school”, which identifies the need for structural policies and structural reforms as a precondition for spurring enduring growth. It rightly draws attention to the power of institutions in reconciling the economic incentives of different actors - private agents or governments. But it may downplay the harm that fluctuations in demand and incomes could potentially cause to economies. Also, the institutionalists may have a tendency to worship the rule of current law. Thus, it may fail to see the shortcomings of the legal framework in place in terms of preventing the economy from spiralling off to bad equilibria with no prospect of return.
A synthesis of these traditions is what we need for the euro area. One can call this “dynamic institutionalism”. Ideally, it should take the optimisation framework of macroeconomics and apply it to institutional design. Such an approach can make an important contribution to charting out the transition to new steady states - as identified, for example, by the Five Presidents' report. It should do this in a way that respects the unique multinational nature of monetary union and upholds and preserves the mutual responsibility that each nation is expected to have vis-à-vis all the others.

