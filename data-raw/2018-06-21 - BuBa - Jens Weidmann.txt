It is a great pleasure to give the keynote speech at this conference on “Monetary Policy Challenges”, organised jointly by the Banque de France and the Deutsche Bundesbank. This joint conference has already become a tradition. It is held every two to three years, with France and Germany taking it in turns to host the event.
Let me start by thanking both the programme committee – Emmanuel Farhi (Harvard), Emanuel Moench (Bundesbank) and Benoît Mojon (Banque de France) – for their ingenious selection of papers, and our host, Governor Villeroy de Galhau, for providing this delightful venue, for the warm welcome and for the excellent organisation by the Banque de France staff.
Even more remarkable is that, in choosing the 21st of June, the Banque de France has been extremely selfless, as I would understand if many of our French colleagues had preferred to watch France play Peru in the football World Cup rather than attend this afternoon’s panel.
But the 21st of June is also a special day for Germans and the Bundesbank. Exactly 70 years ago, the Deutsche Mark was introduced in what was known as the Trizone – the three zones that were occupied after World War II by France, the United Kingdom and the US, and that were to become West Germany one year later.
We have indeed come a long way since those days, when much of Europe was still ravaged by war.
The Franco-German reconciliation that developed in the following decades and eventually grew into a deep friendship is rightly considered one of the great achievements in European history, and it has been a catalyst for European integration.
Events like today’s bear testimony to this process – as well as to the conviction that, by working together in a spirit of openness, we have a much better chance of mastering the common challenges that confront us.
This certainly also holds for monetary policy – both its role and its conduct – after the Financial and Economic Crisis.
About 2,500 years ago, Greek philosopher Heraclitus of Ephesus found two words to describe a fundamental concept of human life and the world we live in: ????? ??? (panta rhei), he said. Everything flows.
In 1789, Benjamin Franklin took a somewhat lighter view when he joked: “In this world nothing can be said to be certain, except death and taxes”.
Today, I do not intend to talk about death, nor about taxes. Instead, I would like to focus on a few aspects of change and how economists and monetary policymakers grapple with them. This is also a central theme underlying this conference, as I am going to highlight.
From the 1980s onwards, advanced economies experienced a period of remarkable economic stability. Swings in inflation and output growth lessened to such a degree that it came to be known as the “Great Moderation”. 
It was around the time of the Great Moderation that the idea of the inflation targeting framework for monetary policy spread. Committing to keeping inflation low, in many cases at around 2 percent, helped many central banks to anchor people’s inflation expectations and to successfully manage short-term economic fluctuations. New Keynesian models suggested the existence of a “divine coincidence” – that by stabilising inflation, output swings would be minimised as well. 
This was certainly a period of bliss. And hopes were high that it was only the start of many more years of stability to come. Some even dared to ask whether the business cycle had ended. 
In retrospect, one might be forgiven for thinking that it sounded a bit like the “end of history” for monetary policy. And – also in economics – it appears that such high hopes may be a reliable indicator that very soon, the plot will take a surprising turn for the worse.
As we all know, this period of economic calm ended in what today is called the “Great Recession”. Inevitably, several of the convictions underlying the pre-crisis monetary policy framework have been questioned since then.
The pre-crisis consensus held, for example, that monetary policy should focus exclusively on using short-term interest rates in order to stabilise consumer price inflation. It was thought that identifying financial bubbles was costly and ineffective, and that monetary policy’s contribution to financial stability should be confined to mopping up the damage once a bubble had popped.
Now, the debate is on whether to “lean” or to “clean”. Should central banks actively use monetary policy also to prevent the build-up of asset price bubbles? That is, should they “lean against the wind” ex ante, even if no action would otherwise be required from a purely inflation targeting point of view? Or should central banks still confine themselves to cleaning up any possible damage ex post?
Another question pertains to the Phillips curve. Supported by ample monetary policy accommodation, output and employment have recovered from the deep economic slump. But even in the face of tightening labour markets, inflationary pressures have long been subdued. Does this mean that the structural relationships between output and inflation that we took for granted are no longer valid? The Sintra conference, which ended yesterday, delved into this topic in greater detail.
Today’s conference, especially Sessions I and III, will be concerned with other topics that have come to the fore in the aftermath of the crisis: changes in the real economy, for example in market structures, that may also have a bearing on allocative efficiency and monetary policy, and a reassessment of the optimal rate of inflation.
In the remainder of my speech, I will comment on some of these topics as well as on last week’s Governing Council decision.
In particular, Session I focuses on a longer-term trend that may have eluded economists and policymakers alike in previous years – that is, the rise in mark-ups of firms in the US over the last decades.
David Dorn has already pointed out that the increasing share of superstar firms in the US might be at least partly responsible for this trend. As globalisation and technical progress favour the most productive firms in each industry, product market concentration, market power and thus mark-ups tend to increase.
In a recent article, the weekly magazine The Economist suggested that American tech giants had created a “kill-zone” surrounding them. I quote: “Once a young firm enters, it can be extremely difficult to survive. Tech giants try to squash startups by copying them, or they pay to scoop them early to eliminate a threat.” 
Such aggressive behaviour may lead to monopoly distortions, which affect the allocation of resources within an economy. The importance of improving allocative efficiency has already been discussed earlier today by David Baqaee. In his paper with Emmanuel Farhi, he calculates that eliminating mark-ups due to monopoly distortions could raise total factor productivity by as much as 20 percent. This points to the important role that levers such as competition policy can play for economic outcomes.
Indeed, Thomas Philippon is going to argue that EU markets have become more competitive than US markets. Based on OECD data, he and his co-author Germán Gutiérrez find that, due to improved antitrust policy and product market regulations, European markets today are less concentrated and have lower barriers to entry than American markets.
There is more evidence to support the notion that Europe may be different from the US when it comes to mark-ups. A Bundesbank analysis published in our Monthly Report in December 2017 took a closer look at sectoral data for selected European countries, including Germany, France and Italy. The study was unable to find any evidence of a long-term increase in mark-ups. Some estimates even suggest a reduction.
Hence, while many studies – for a variety of reasons like the availability of suitable, high quality data – focus on the US, not all conclusions necessarily apply to other economies. Therefore, conducting similar analyses for other countries as well – and providing the data required to do so – is both indispensable and insightful.
Now, given the findings just mentioned, can we say that all is well in the EU when it comes to competition and the efficient allocation of resources?
First, while barriers to entry are very low for most goods, this might be less so for services.
Second, while antitrust policy has improved and barriers to entry have been lowered, a different source of potential resource misallocation seems present in the EU today. It is related to the banking system.
Banks that do not have a viable business model, and at the same time carry a larger amount of non-performing loans on their books, are at a higher risk of not putting funds to their most efficient use.
These banks tend to prolong their loans to legacy customers so as not to have to take a potential financial loss. Often, however, they will subsequently also grant fewer new loans to other customers. This means that funding remains with less productive firms instead of being channelled towards more innovative firms.
According to this line of reasoning, weak banks tend to foster weak firms. The ensuing inefficient distribution of funding can dampen an economy’s innovativeness and dynamism.
Work by Ricardo Caballero and others studying Japan’s experience from the 1990s onwards has highlighted this relationship. The case of Europe may be more debatable. However, ECB research has provided evidence of this relationship for euro area periphery countries. 
Studies by the OECD confirm that a non-negligible percentage of firms in some EU countries can be classified as ”zombie firms”. For instance, in 2013, 28 percent of capital resources in Greece, 19 percent in Italy and 16 percent in Spain were sunk in firms that were unable to cover their cost of capital.
Economists Fabiano Schivardi, Enrico Sette and Guido Tabellini have shown how the health of the banking system influences capital allocation. They estimate that credit misallocation in Italy reduced annual GDP growth by between 0.2 and 0.35 percentage point in the 2008 to 2013 period.
What can be done to improve capital allocation? Research suggests that effective restructuring and resolution regimes incentivise banks to grant credit prudently and can therefore improve economic growth.
Progress has been made with regard to the reduction of non-performing loans on the books of euro area banks. But more needs to be done to resolve this issue as quickly as possible.
In countries with low-NPL banking systems, it would also help to alleviate concerns about the risks which might have to be shouldered when moving to a European Deposit Insurance Scheme.
The main takeaway from Session I seems to be that levers such as competition policies have to be pulled in order to improve allocative efficiency. This resonates well with the message which the Governing Council has been stressing for years now: Structural policies are key to shifting the economy towards a higher growth path.
However, the findings on mark-ups may also have important implications for inflation. Here, it may be convenient to distinguish between longer-term and cyclical aspects.
If mark-ups have indeed risen in the United States over a long period of time, they should have produced upward pressure on prices, all else equal. Along these lines, Jan Eeckhout may suggest later that the US inflation rate was lifted by about 1 percentage point per year from 1980 to 2014, as the average mark-up rose.
Thus, absent this effect, inflation would have even been markedly lower in recent years than it actually was. This would render the phenomenon of subdued inflation in the face of a tighter US labour market all the more puzzling.
On the other hand, the Bundesbank study I just mentioned finds evidence of a procyclical behaviour of mark-ups in European countries. Especially during the crisis years, the weakness of aggregate demand appears to have compressed profit margins.
Conversely, mark-ups may rise again as the economic upturn progresses. This normalisation could temporarily increase inflation pressures in European countries.
To sum up, a closer look at market structures can shed more light on structural determinants of inflation. But at least according to the papers presented today they do not answer the question why it has been so sluggish for such a long period.
Subdued inflation and low interest rates characterised the macroeconomic environment in recent years. In the US, interest rates stayed at around the zero lower bound for seven years. Currently, the federal funds rate is bound to a target range of 1.75 percent to 2 percent. In the euro area, the deposit facility rate has been zero or even lower since mid-2012, and it will still take some time until we will exceed that level again.
Much of the length of this period of ultra-low interest rates has to do with the depth of the slump during the crisis. However, some observers fear that the economy may have reached a new normal, pointing to a long-term decline in interest rates.
In that case, the central bank’s task of achieving price stability may have become more difficult, because it means a higher probability of monetary policy hitting the effective lower bound.
Economic theory suggests several ways to mitigate this risk. Price level targeting or nominal GDP targeting advocate a conceptually more profound change in monetary policy strategy by introducing an element of self-correction: inflation expectations would rise automatically for some time after inflation had been unusually low. 
A more conventional solution is to compensate for the lost room to manoeuvre by raising the inflation target permanently. In today’s Session III, Jordi Galí will explore the interactions between the optimal rate of inflation and the natural rate of interest.
He and his co-authors try to estimate the costs and benefits of a higher inflation target when there is a risk of monetary policy hitting the lower bound. Obviously, there is a trade-off between the welfare costs of inflation and the cost of target misses at the lower bound.
However, within the context of this policy trade-off there is a subtle issue that I would like to mention, since it is underappreciated in the policy debate. The higher the inflation target, the more firms become “forward-looking”. With higher trend inflation, the price-resetting firm sets a higher price, as it anticipates that trend inflation is going to erode its relative price in the future.
As a consequence, the relative importance of current marginal costs, and therefore of the output gap, decreases. Thus, if the central bank raises the inflation target, the (short-run) New Keynesian Phillips curve flattens, and the inflation rate becomes less sensitive to variations in current output. Or, to put it differently, for a given change of the inflation rate, the central bank has to change its policy rate correspondingly by more. It therefore loses some of the additional wiggle-room gained through the higher target. The relevance of this trade-off depends on assumptions regarding the price setting behaviour.
According to Jordi’s model, the optimal inflation target for the euro area is 1.5 percent. When parameter uncertainty is allowed for, the figure increases to 2.2 percent. And each fall of the natural rate of interest by one percentage point should lead to an increase of the inflation target by 0.9 percentage point.
In my opinion, contributions like Jordi’s are particularly helpful as they provide a workable framework within which to weigh different trade-offs inherent in an economic policy decision. As with all models, the paper abstracts from certain aspects in order to zoom in on the interaction of a particular set of variables. In this case, I believe that some of the aspects not included in this model might shift the overall assessment of the benefits and cost of a higher inflation target significantly.
The risk of de-anchoring inflation expectations seems particularly relevant in this regard. Ben Bernanke once put it like this: “If we were to go to 4 percent and say we’re going to 4 percent, we would risk a lot of … hard-won credibility, because folks would say, well, if we go to 4 percent, why not go to 6 percent? It’d be very difficult to tie down expectations at 4 percent.”
As we describe in our most recent Monthly Report, which was published earlier this week, Bernanke’s claim can be supported by a prototypical New Keynesian framework with adaptive learning and a central bank following a simple Taylor rule. Here, a higher inflation target makes reaching a stable equilibrium more difficult.
Moreover, research by Klaus Adam and Henning Weber suggests that the optimal rate of inflation at the firm level has declined in the US over time, as Klaus is going to argue tomorrow. Other studies, for example by Coibion and Gorodnichenko, have provided evidence that the reduction in US trend inflation in the 1980s was crucial for the subsequent stabilisation of inflation and inflation expectations during the Great Moderation.
Moving to a higher inflation target could jeopardise such stabilisation gains. For reasons like these, I am convinced that our euro area inflation target of below, but close to, 2 percent remains appropriate.
Reaching this target has proven challenging for some time now, as I pointed out at the beginning of my speech. But I am convinced that we are finally getting there.
On the one hand, the upswing in the euro area continues to rest on a broad base, and is expected to continue, notwithstanding somewhat higher downside risks. On the other hand, according to the Eurosystem’s most recent projections, price pressures will pick up again due to further rises in aggregate capacity utilisation. Domestic inflation, as measured for example by the change in the HICP excluding energy and food, should increase steadily, from 1.1 percent this year to 1.9 percent in 2020. As the profile of energy prices is assumed to be hump-shaped, headline inflation is expected to stay flat at 1.7 percent in the years 2018 to 2020. But even this figure would be broadly in keeping with our definition of price stability over the medium term.
As an aside, additional confidence that inflation is on a sustainable adjustment path back to its target can also be derived from the treatment of housing in the HICP: only rents actually show up in the inflation rate, but not the cost of owner-occupied housing – unlike, for example, CPI inflation in the US.
While consumer price indices with and without owner-occupied housing are rather indistinguishable over the long term, at times they can differ markedly. For the euro area, measures that include the cost of owner-occupied housing yield inflation rates slightly above the official HICP rate in recent years. Daniel Gros has highlighted this gap in a recent analysis for the European Parliament, basically confirming previous calculations by ECB staff.
Let me be absolutely clear: of course, this is not a call for cherry-picking measures of inflation. That would be a sure-fire way to jeopardise credibility.
But the gap between inflation measures is one additional aspect that can give us even more confidence that we are on the right track. It lends further support to the assessment of the ECB’s Governing Council that the pick-up in inflation has become sufficiently robust to signal an end to the net asset purchases by the end of 2018. And it is another example of differences between the US and the euro area that economists need to keep in mind.
Even after the net purchases have come to an end, the monetary policy stance will remain very accommodative, given the large stock of assets on the Eurosystem’s balance sheets, the ongoing reinvestment of proceeds from maturing assets, and the Governing Council’s signal that its policy rates will remain at their present levels at least through the summer of 2019.
Hence, ending the net purchases is most likely just the first step on a multi-year path of a gradual monetary policy normalisation. And that’s precisely why it has been so important to actually get the ball rolling. 
Ladies and gentlemen
Coming back to Benjamin Franklin, I am convinced that there are other certainties in life besides death and taxes. The ability of monetary policy to achieve price stability is one of them.
And as regards Heraclitus, he also said: “You cannot step into the same river twice.” The river changes constantly, as the water flows. But this is not meant to be nihilistic – after all, in spite of the changes, the river remains a river.
Similarly, as regards monetary policy and the challenges it faces, the world is subject to constant change, but there is also continuity.
I now look forward to exploring promising avenues of thought, in an effort to capture both this change and the continuity with you, and wish us all an exciting and rewarding conference!
On that note, I am now looking forward to the answers our esteemed participants come up with!
